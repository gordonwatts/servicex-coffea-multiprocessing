{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will fetch data from ServiceX and process it via coffea on a local `ray` cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_it_sync import make_sync\n",
    "import matplotlib.pyplot as plt\n",
    "from coffea import hist, processor\n",
    "\n",
    "from sx_multi import FuncAdlQastle, sx_event_stream, process_coffea_ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the data\n",
    "\n",
    "We want to pull back only electrons with $p_T > 30$ GeV, and $abs(\\eta)<2.5$. Aid since this is a super-simple algorithm - we will limit it to those events that have just two electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FuncAdlQastle()\n",
    "leptons_per_event_query = ds \\\n",
    "        .Select(lambda e: e.Electrons(\"Electrons\")) \\\n",
    "        .Select(lambda eles: eles.Where(lambda e: e.pt()/1000.0 > 30.0)) \\\n",
    "        .Select(lambda eles: eles.Where(lambda e: abs(e.eta()) < 2.5)) \\\n",
    "        .Where(lambda eles: len(eles) == 2) \\\n",
    "        .Select(lambda ls: (ls.Select(lambda e: e.pt()/1000.0), ls.Select(lambda e: e.eta()), ls.Select(lambda e: e.phi()), ls.Select(lambda e: e.m()/1000.0))) \\\n",
    "        .AsROOTTTree('data.root', 'mytree', ('ElePt', 'EleEta', 'ElePhi', 'EleM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the dataset identifier we want to be scanning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "did = 'mc15_13TeV:mc15_13TeV.361106.PowhegPythia8EvtGen_AZNLOCTEQ6L1_Zee.merge.DAOD_STDM3.e3601_s2576_s2132_r6630_r6264_p2363_tid05630052_00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Coffea Process Function\n",
    "\n",
    "This will get the data from above (in servicex). It gets access to a single file and must open it, and then build the invar mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZMassProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            \"sumw\": processor.defaultdict_accumulator(float),\n",
    "            \"mass\": hist.Hist(\n",
    "                \"Events\",\n",
    "                hist.Bin(\"mass\", \"$Z_{ee}$ [GeV]\", 60, 60, 120),\n",
    "            ),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, events):\n",
    "        output = self.accumulator.identity()\n",
    "        import awkward1 as ak\n",
    "\n",
    "        # Because we aren't using a scheme, build one by hand.\n",
    "        electrons = ak.zip({\n",
    "            \"pt\": events.ElePt,\n",
    "            \"eta\": events.EleEta,\n",
    "            \"phi\": events.ElePhi,\n",
    "            \"mass\": events.EleM,\n",
    "            \"charge\": events.EleM,\n",
    "        }, with_name=\"PtEtaPhiMCandidate\")\n",
    "\n",
    "        # form the invar mass, plot.\n",
    "        cut = (ak.num(electrons) == 2)\n",
    "        diele = electrons[cut][:, 0] + electrons[cut][:, 1]\n",
    "\n",
    "        output[\"sumw\"]['bogus'] += len(events)\n",
    "        output[\"mass\"].fill(\n",
    "            mass=diele.mass,\n",
    "        )\n",
    "\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, final_results):\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run through ray\n",
    "\n",
    "First, the data stream from servicex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "servicex_data = sx_event_stream(did, leptons_per_event_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a local `ray` cluster. We'll setup 10 workers, but there is probably a better way to tune this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-19 01:09:03,845\tINFO services.py:1090 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will now run each sx resulting file through the processor above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_results = process_coffea_ray(servicex_data, ZMassProcessor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot - attempt to update the plot as it comes in (but don't know how to do that!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plot_stream(accumulator_stream):\n",
    "  async for coffea_info in accumulator_stream:\n",
    "    # Need to ask coffea folks how to anomate this!\n",
    "    hist.plot1d(coffea_info['mass'])\n",
    "    plt.show()\n",
    "  return coffea_info\n",
    "\n",
    "await plot_stream(accumulated_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, the data is produced on UChicago's `river` cluster and downloaded locally to where this notebook is running (for the above, this is a house in Canada). Watching my network connection, even with 10 workers, it isn't saturated. And is definately slower than the `funcx`. However, if there was a `ray` cluster located on `river`, one could connect there and then the same efficiencies seen with `funcx` would be seen here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
